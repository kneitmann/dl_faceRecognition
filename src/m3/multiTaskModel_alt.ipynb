{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Task Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "\n",
    "from loadData_alt import createDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log parameters\n",
    "model_name = 'multiTaskModel_alt2'\n",
    "savedModelPath = f'../../log/saved_models/{model_name}'\n",
    "tb_log_dir = f'../../log/tensorboard/{model_name}'\n",
    "cp_filepath = f'../../log/cps/{model_name}/latest_weights.h5'\n",
    "\n",
    "# Dynamic hyperparameters\n",
    "learningRate = 0.001\n",
    "doDataAugmentation = True\n",
    "doFineTuning = True\n",
    "dropoutRate = 0.25\n",
    "width_multiplier = 1\n",
    "depth_multiplier = 1\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # Checkpoint callback                    \n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "                    filepath=cp_filepath, \n",
    "                    verbose=1, \n",
    "                    save_weights_only=True),\n",
    "\n",
    "    # Tensorboard callback\n",
    "    keras.callbacks.TensorBoard(log_dir=tb_log_dir, histogram_freq=1),\n",
    "\n",
    "    # Early Stopping callback\n",
    "    # keras.callbacks.EarlyStopping(\n",
    "    #                 monitor=\"val_loss\",\n",
    "    #                 patience=2,\n",
    "    #                 verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height = 160\n",
    "image_width = 160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.RandomRotation(0.1),\n",
    "        keras.layers.RandomBrightness(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ds, validation_ds = createDataset('../../data/m3/training', batch_size, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_ds = createDataset('../../data/m3/training', batch_size, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the ResNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "# Loading either the MobileNet architecture model or the previously saved model, and freeze it for transfer learning\n",
    "mobilenet = MobileNet(\n",
    "                input_shape=(image_height, image_width, 3), # Optional shape tuple, only to be specified if include_top is False\n",
    "                alpha=width_multiplier, # Controls the width of the network. (Width multiplier)\n",
    "                depth_multiplier=depth_multiplier, # Depth multiplier for depthwise convolution. (Resolution multiplier)\n",
    "                dropout=dropoutRate, # Dropout rate. Default to 0.001.\n",
    "                weights=\"imagenet\",\n",
    "                input_tensor=None,\n",
    "                pooling='avg', # Optional pooling mode for feature extraction when include_top is False. (None, avg, max)\n",
    "                include_top=False\n",
    "                )\n",
    "           \n",
    "# Freeze the base model\n",
    "mobilenet.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(image_height, image_width, 3))\n",
    "# Data Augmentation on input\n",
    "if(doDataAugmentation):\n",
    "    inputs = data_augmentation(inputs)\n",
    "\n",
    "# Running base model in inference mode\n",
    "base_model = mobilenet(inputs, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Task 1 (Face Detection) Top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dense layer\n",
    "face_head = tf.keras.layers.Dense(256, activation='leaky_relu')(base_model)\n",
    "face_head = tf.keras.layers.Dense(128, activation='leaky_relu')(face_head)\n",
    "\n",
    "# Final layer for binary classification\n",
    "face_outputs = keras.layers.Dense(1, activation='sigmoid', name='face_output')(face_head)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Task 2 (Mask Detection) Top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dense layer\n",
    "mask_head = tf.keras.layers.Dense(256, activation='leaky_relu')(base_model)\n",
    "mask_head = tf.keras.layers.Dense(128, activation='leaky_relu')(mask_head)\n",
    "\n",
    "# Final layer for binary classification\n",
    "mask_outputs = keras.layers.Dense(1, activation='sigmoid', name='mask_output')(mask_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Task 3 (Age Prediction) Top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Dense layer\n",
    "age_head = tf.keras.layers.Dense(512, activation='leaky_relu')(base_model)\n",
    "age_head = tf.keras.layers.Dense(256, activation='leaky_relu')(age_head)\n",
    "\n",
    "# Final layer for binary classification\n",
    "age_outputs = keras.layers.Dense(122, activation='softmax', name='age_output')(age_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_class_weights = np.ones((122,122), dtype=np.float32)\n",
    "age_class_weights[len(age_class_weights)-1, :] = 0.0 # Last class will be ignored (invalid data)\n",
    "age_class_weights[:, len(age_class_weights)-1] = 0.0 # Last class will be ignored (invalid data)\n",
    "\n",
    "def WeightedCategoricalCrossentropy(y_true, y_pred):\n",
    "    weights = tf.convert_to_tensor(age_class_weights)\n",
    "    mask = K.sum((K.dot(y_true,weights) * y_pred), axis=1)\n",
    "\n",
    "    return K.categorical_crossentropy(y_true, y_pred) * K.sum((K.dot(y_true,weights) * y_pred), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and compiling the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 160, 160, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " mobilenet_1.00_160 (Functional  (None, 1024)        3228864     ['input_8[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          262400      ['mobilenet_1.00_160[6][0]']     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          262400      ['mobilenet_1.00_160[6][0]']     \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 512)          524800      ['mobilenet_1.00_160[6][0]']     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['dense[6][0]']                  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          32896       ['dense_2[6][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 256)          131328      ['dense_4[6][0]']                \n",
      "                                                                                                  \n",
      " face_output (Dense)            (None, 1)            129         ['dense_1[6][0]']                \n",
      "                                                                                                  \n",
      " mask_output (Dense)            (None, 1)            129         ['dense_3[6][0]']                \n",
      "                                                                                                  \n",
      " age_output (Dense)             (None, 122)          31354       ['dense_5[6][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,507,196\n",
      "Trainable params: 1,278,332\n",
      "Non-trainable params: 3,228,864\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = keras.Model(inputs, [face_outputs, mask_outputs, age_outputs])\n",
    "#keras.utils.plot_model(model)\n",
    "\n",
    "# Using a joint loss function for the three tasks:\n",
    "# [ Loss = gamma * Loss_task1 + gamma * Loss_task2 + gamma * Loss_task3 ]\n",
    "# Because every task is dependant on every other task, the model receives the loss of every task when gamma > 0\n",
    "\n",
    "gamma = 1\n",
    "\n",
    "model.compile(\n",
    "      optimizer=keras.optimizers.Adam(0.001), # Learning Rate?\n",
    "            loss={\n",
    "                  'face_output': keras.losses.BinaryCrossentropy(), \n",
    "                  'mask_output': keras.losses.BinaryCrossentropy(),\n",
    "                  'age_output': WeightedCategoricalCrossentropy\n",
    "                  },\n",
    "            loss_weights={\n",
    "                  'face_output': 0.33 * gamma, \n",
    "                  'mask_output': 0.33 * gamma,\n",
    "                  'age_output': 0.33 * gamma\n",
    "                  }, \n",
    "            metrics={\n",
    "                  'face_output': keras.metrics.BinaryAccuracy(), \n",
    "                  'mask_output': keras.metrics.BinaryAccuracy(),\n",
    "                  'age_output': keras.metrics.CategoricalAccuracy()\n",
    "                  },\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "OperatorNotAllowedInGraphError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\Zolkin\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Zolkin\\AppData\\Local\\Temp\\ipykernel_12964\\4257144270.py\", line 8, in WeightedCategoricalCrossentropy  *\n        for x, y in mask:\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      2\u001b[0m             training_ds,\n\u001b[0;32m      3\u001b[0m             validation_data\u001b[39m=\u001b[39;49mvalidation_ds,\n\u001b[0;32m      4\u001b[0m             epochs\u001b[39m=\u001b[39;49mepochs, \n\u001b[0;32m      5\u001b[0m             callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m      6\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Zolkin\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Zolkin\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1269\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1267\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1269\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[0;32m   1270\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1271\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mOperatorNotAllowedInGraphError\u001b[0m: in user code:\n\n    File \"c:\\Users\\Zolkin\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Zolkin\\AppData\\Local\\Temp\\ipykernel_12964\\4257144270.py\", line 8, in WeightedCategoricalCrossentropy  *\n        for x, y in mask:\n\n    OperatorNotAllowedInGraphError: Iterating over a symbolic `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            training_ds,\n",
    "            validation_data=validation_ds,\n",
    "            epochs=epochs, \n",
    "            callbacks=callbacks\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if doFineTuning:\n",
    "      model_name = model_name + '_ft'\n",
    "      mobilenet.trainable = True\n",
    "      model.summary()\n",
    "\n",
    "      model.compile(\n",
    "            optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "            loss={\n",
    "                  'face_output': keras.losses.BinaryCrossentropy(), \n",
    "                  'mask_output': keras.losses.BinaryCrossentropy(),\n",
    "                  'age_output': keras.losses.SparseCategoricalCrossentropy()\n",
    "                  },\n",
    "            loss_weights={\n",
    "                  'face_output': gamma, \n",
    "                  'mask_output': gamma,\n",
    "                  'age_output': gamma\n",
    "                  }, \n",
    "                  metrics=['accuracy']\n",
    "      )\n",
    "\n",
    "      model.fit(training_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(savedModelPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {results[0]}; Accuracy: {results[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/tutorials/images/classification\n",
    "\n",
    "img = tf.keras.utils.load_img(\n",
    "    '../../data/m3/training/face/noMask/1_0_34_512938.jpg', target_size=(image_height, image_width)\n",
    ")\n",
    "img_array = tf.keras.utils.img_to_array(img)\n",
    "img_array_batch = tf.expand_dims(img_array, 0) # Create a batch\n",
    "\n",
    "preds = model.predict(img_array_batch)\n",
    "age_output_indexes = np.array([i for i in range(0, 120)])\n",
    "apparent_predictions = np.sum(preds[2][0] * age_output_indexes)\n",
    "\n",
    "print(f\"Face: {preds[0][0]*100}%\")\n",
    "print(f\"Mask: {preds[1][0]*100}%\")\n",
    "print(f\"Age: {np.argmax(preds[2][0])}\")\n",
    "\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "plt.imshow(img)\n",
    "plt.title(\"Face: {:.2f}% | Mask: {:.2f}% | Age: {:.0f}\".format(preds[0][0][1]*100, preds[1][0][1]*100, apparent_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tensorflow_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cb093c5cba338e940f2218658681cebd9a5d8f8bec398f9f020da08f4168391d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
